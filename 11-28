What needs to be edited: 
1. there is still an issue with the debt_to_income_ratio variable. The formatting of observations was messy and it doesn't appear to have been cleaned properly. It may be a good predicotr so probably worth fixing.
2. We may want to save the cleaned_df, or whichever df is used for running models, as a csv so we don't have to reclean the original dataset every time.  
	- it might even be worth creating a .shp file with geographic characteristics for creating maps and saving the .shp separately.
4. Might be useful to have some more visualizations, charts, graphs, maps. Variable significance as determined by our final models may also illuminate which variables would benefit from graphing or mapping. 
5. Since our logit is multinomial (3 possible outcomes), we must specify 'multinomial' when using sklearn package. 
6. The single tree is not very useful to analysis. Something like a Random Forest may be better, since it determines feature importance by running up to 100 trees. 

I have code setup for saving teh cleaned df and creating a .shp that wil be executed once the cleaned_df is in its final form.

I see the final Repository looking like: 
Code (folder)
	- data merging script (hmda + census) 
	- data cleaning script
	- chart making/mapping script
	modelling/model tuning script
Raw Data
	- original MA HMDA data csv
Saved Data
	- merged hmda + census csv file
	- cleaned data csv
	cleaned data/geogprahical .shp file
Output
	- final models script
	- data used for final models (csv) 
